{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#Lgbm\" data-toc-modified-id=\"Lgbm-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Lgbm</a></span><ul class=\"toc-item\"><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "import spacy\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0,nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 0 to 50054\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    50000 non-null  object\n",
      " 1   toxic   50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44853\n",
       "1     5147\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В столбце text присутсвуют слова с заглавной буквы, комментарии написанные капсом и посторонние знаки с отступами \\n. отношение токсичных кооментариев к обычным 1/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.102940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.303884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              toxic\n",
       "count  50000.000000\n",
       "mean       0.102940\n",
       "std        0.303884\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww  he matches this background colour i m s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww  he matches this background colour i m s...      0\n",
       "2  hey man  i m really not trying to edit war  it...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you  sir  are my hero  any chance you remember...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "df['text'] = df['text'].map(lambda x: clean_text(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def lemmatize(text):\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)   \n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5def3027f9234281b3cba2a3ab13442f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww   he match this background colour I m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man   I m really not try to edit war   it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edit make under my usernam...      0\n",
       "1  d aww   he match this background colour I m se...      0\n",
       "2  hey man   I m really not try to edit war   it ...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "    global nlp\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "df['text'] = df['text'].progress_apply(lemmatize) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После очисти от лишних знаков и последующей лемматизации данные подготовлены для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df.drop('toxic', axis=1)\n",
    "target = df['toxic']\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(feature, target, test_size = 0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 20, 'clf__class_weight': 'balanced'}\n",
      "0.7545638174238231\n"
     ]
    }
   ],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression(random_state=12345, max_iter = 10000))])\n",
    "params = {'clf__C': [10, 20, 100],\n",
    "          'clf__class_weight': ['balanced', None]}\n",
    "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1)\n",
    "lr_grid.fit(feature_train['text'], target_train)\n",
    "lr_best_paramms = lr_grid.best_params_\n",
    "print(lr_best_paramms)\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__learning_rate': 0.15, 'clf__max_depth': 30, 'clf__n_estimators': 200}\n",
      "0.7462941411000178\n"
     ]
    }
   ],
   "source": [
    "lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LGBMClassifier(random_state=12345))])\n",
    "params = {\n",
    "  'clf__n_estimators': [200],\n",
    "  'clf__learning_rate': [0.15,0.25],\n",
    "  'clf__max_depth': [8, 10, 30]}\n",
    "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1)\n",
    "lgb_grid.fit(feature_train['text'], target_train)\n",
    "lgb_best_params = lgb_grid.best_params_\n",
    "print(lgb_best_params)\n",
    "print(lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__max_depth': None, 'clf__n_estimators': 100}\n",
      "0.7031738658621839\n"
     ]
    }
   ],
   "source": [
    "rfc_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', RandomForestClassifier(random_state=12345))])\n",
    "params = {\n",
    "  'clf__n_estimators': [20, 100],\n",
    "  'clf__max_depth': [8, 10, None]}\n",
    "rfc_grid = GridSearchCV(estimator=rfc_pipe, param_grid=params, cv=3, scoring='f1', n_jobs=-1)\n",
    "rfc_grid.fit(feature_train['text'], target_train)\n",
    "rfc_best_params = rfc_grid.best_params_\n",
    "print(rfc_best_params)\n",
    "print(rfc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитали метрики f1 для тренировочной выборок\n",
    "\n",
    "LogisticRegression на тренировочной выборке f1 = 0.755\n",
    "\n",
    "Lgbm на тренировочной выборке f1 = 0.746\n",
    "\n",
    "RandomForestClassifier на тренировочной выборке f1 = 0.703\n",
    "\n",
    "Наилучший результат у LogisticRegression расчитаем метрику f1 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7557894736842106"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred = lr_grid.best_estimator_.predict(feature_test['text'])\n",
    "f1_score(target_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы была выполнена лематизация, чистка текста библиотекой spacy, так же очистили от мусоа и неинформативных слов и символов, оставим только слова. В связи с ограничениями платформы пришлось использовать 50000 тыс строк из начального датафрейма.    \n",
    "\n",
    "Было обучено несколько алгоритмов, подобраны гипперпараметры посчитана f1  на тестовой выборке, получено значение 0,756. \n",
    "\n",
    "Интернет магазину викишоп будет предложен именно этот алгоритм для классификации коментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 20638,
    "start_time": "2023-10-26T16:56:30.970Z"
   },
   {
    "duration": 374,
    "start_time": "2023-10-26T16:56:51.610Z"
   },
   {
    "duration": 2437,
    "start_time": "2023-10-26T16:57:25.478Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-26T16:57:47.744Z"
   },
   {
    "duration": 4465,
    "start_time": "2023-10-26T16:58:52.853Z"
   },
   {
    "duration": 843,
    "start_time": "2023-10-26T16:58:57.320Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-26T16:58:58.165Z"
   },
   {
    "duration": 29,
    "start_time": "2023-10-26T16:58:58.180Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-26T16:58:58.211Z"
   },
   {
    "duration": 38,
    "start_time": "2023-10-26T16:58:58.220Z"
   },
   {
    "duration": 3311,
    "start_time": "2023-10-26T16:58:58.260Z"
   },
   {
    "duration": 1311,
    "start_time": "2023-10-26T16:59:01.573Z"
   },
   {
    "duration": 5847,
    "start_time": "2023-10-26T17:05:28.011Z"
   },
   {
    "duration": 36,
    "start_time": "2023-10-26T17:05:33.862Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-26T17:05:33.899Z"
   },
   {
    "duration": 41,
    "start_time": "2023-10-26T17:05:33.915Z"
   },
   {
    "duration": 40,
    "start_time": "2023-10-26T17:05:33.958Z"
   },
   {
    "duration": 37,
    "start_time": "2023-10-26T17:05:34.000Z"
   },
   {
    "duration": 35,
    "start_time": "2023-10-26T17:05:34.039Z"
   },
   {
    "duration": 594,
    "start_time": "2023-10-26T17:05:34.076Z"
   },
   {
    "duration": 8483,
    "start_time": "2023-10-26T17:05:34.673Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-26T17:05:43.159Z"
   },
   {
    "duration": 1166,
    "start_time": "2023-10-26T17:05:43.169Z"
   },
   {
    "duration": 94026,
    "start_time": "2023-10-26T17:05:44.336Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-26T17:07:18.363Z"
   },
   {
    "duration": 2430,
    "start_time": "2023-10-26T17:07:18.450Z"
   },
   {
    "duration": 27,
    "start_time": "2023-10-26T17:07:20.882Z"
   },
   {
    "duration": 350,
    "start_time": "2023-10-26T17:07:20.911Z"
   },
   {
    "duration": 21,
    "start_time": "2023-10-26T17:08:15.747Z"
   },
   {
    "duration": 4390,
    "start_time": "2023-10-26T17:21:11.733Z"
   },
   {
    "duration": 36,
    "start_time": "2023-10-26T17:21:16.125Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-26T17:21:16.163Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-26T17:21:16.179Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-26T17:21:16.191Z"
   },
   {
    "duration": 22,
    "start_time": "2023-10-26T17:21:16.202Z"
   },
   {
    "duration": 26,
    "start_time": "2023-10-26T17:21:16.226Z"
   },
   {
    "duration": 525,
    "start_time": "2023-10-26T17:21:16.254Z"
   },
   {
    "duration": 8552,
    "start_time": "2023-10-26T17:21:16.781Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-26T17:21:25.344Z"
   },
   {
    "duration": 1069,
    "start_time": "2023-10-26T17:21:25.351Z"
   },
   {
    "duration": 251228,
    "start_time": "2023-10-26T17:21:26.422Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-26T17:25:37.651Z"
   },
   {
    "duration": 2434,
    "start_time": "2023-10-26T17:25:37.676Z"
   },
   {
    "duration": 37,
    "start_time": "2023-10-26T17:25:40.112Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-26T17:25:40.151Z"
   },
   {
    "duration": 804,
    "start_time": "2023-10-26T17:37:56.904Z"
   },
   {
    "duration": 13766,
    "start_time": "2023-10-26T17:38:07.352Z"
   },
   {
    "duration": 277,
    "start_time": "2023-10-26T17:38:21.120Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-26T17:38:21.398Z"
   },
   {
    "duration": 33,
    "start_time": "2023-10-26T17:38:21.414Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-26T17:38:21.450Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-26T17:38:21.458Z"
   },
   {
    "duration": 1108,
    "start_time": "2023-10-26T17:38:21.479Z"
   },
   {
    "duration": 678,
    "start_time": "2023-10-26T17:38:22.589Z"
   },
   {
    "duration": 811995,
    "start_time": "2023-10-26T17:38:23.269Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-26T17:51:55.265Z"
   },
   {
    "duration": 745475,
    "start_time": "2023-10-26T17:51:55.276Z"
   },
   {
    "duration": 1448,
    "start_time": "2023-10-26T18:04:20.753Z"
   },
   {
    "duration": 2764770,
    "start_time": "2023-10-26T18:04:22.203Z"
   },
   {
    "duration": 2088,
    "start_time": "2023-10-26T18:50:26.976Z"
   },
   {
    "duration": 283410,
    "start_time": "2023-10-26T18:50:29.066Z"
   },
   {
    "duration": 3490,
    "start_time": "2023-10-26T18:55:12.478Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-26T18:55:15.970Z"
   },
   {
    "duration": 4916,
    "start_time": "2023-10-27T06:28:54.805Z"
   },
   {
    "duration": 1052,
    "start_time": "2023-10-27T06:28:59.723Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-27T06:29:03.580Z"
   },
   {
    "duration": 22,
    "start_time": "2023-10-27T06:29:05.323Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-27T06:29:06.529Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-27T06:29:10.133Z"
   },
   {
    "duration": 1269,
    "start_time": "2023-10-27T06:29:12.712Z"
   },
   {
    "duration": 698,
    "start_time": "2023-10-27T06:29:16.119Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
